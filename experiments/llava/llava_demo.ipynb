{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7777a961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "\n",
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "\n",
    "sys.path.append('../..')\n",
    "from fast_nystrom_attention import LlavaNextForConditionalGenerationFNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0936aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19586c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fc57ae2e6e4547a839d296e624a48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_ID = \"llava-hf/llava-v1.6-vicuna-7b-hf\"\n",
    "DTYPE = torch.bfloat16\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "fna_config = {\n",
    "    'fna_layers': [], # range(12, 32),\n",
    "    'num_sample': 256,\n",
    "    'sampling_strategy': 'random',\n",
    "    'resample_fps': False,\n",
    "}\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(MODEL_ID, use_fast=False)\n",
    "model = LlavaNextForConditionalGenerationFNA.from_pretrained(\n",
    "    MODEL_ID, \n",
    "    fna_config=fna_config, \n",
    "    torch_dtype=DTYPE, \n",
    "    device_map=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2a879f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 tokens in 9.15s (54.64 tokens/s)\n",
      "USER: \n",
      "Write a story about this image. ASSISTANT: In the heart of a mystical forest, there was a bridge that seemed to be a gateway to another world. The bridge, made of sturdy wood and supported by sturdy stone pillars, spanned a small river that flowed with a gentle current. It was a place where the veil between the worlds was thin, and the whispers of the ancient spirits could be heard.\n",
      "\n",
      "One stormy night, as the rain lashed against the leaves and the wind howled through the trees, a lone traveler ventured into the forest. The traveler, a seeker of knowledge and a believer in the power of the unknown, had heard tales of the bridge and its mysterious properties.\n",
      "\n",
      "As the traveler approached the bridge, the rain grew heavier, and the wind grew stronger. The trees swayed wildly, and the river swelled, its waters rising to meet the bridge. The traveler paused, unsure if they should continue. But something drew them forward, a force that was not of this world.\n",
      "\n",
      "The traveler stepped onto the bridge, and as they did, the world around them shifted. The rain stopped, the wind died down, and the trees stood still. The traveler looked around and saw that the bridge was not just a pathway but a doorway to another realm.\n",
      "\n",
      "Through the doorway, the traveler could see a world that was both familiar and alien. It was a place of ancient ruins and hidden temples, where the secrets of the universe were said to be held. The traveler knew that they had stumbled upon something extraordinary, and they were filled with a sense of awe and wonder.\n",
      "\n",
      "As the traveler stepped through the doorway, they were greeted by a figure that seemed to be made of light itself. The figure spoke in a voice that was both soothing and commanding, saying, \"Welcome, traveler. You have found the bridge to the unknown. Cross it with caution, for the path ahead is fraught with danger and mystery.\"\n",
      "\n",
      "The traveler, now filled with courage and curiosity, stepped forward onto the path that lay beyond the bridge. They knew that they would face challenges and that the journey would be filled with unknowns. But they were driven by the desire to uncover the secrets of the universe and\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "image = Image.open('forest.jpg')\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Write a story about this image.\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "inputs = processor(image, prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "# autoregressively complete prompt\n",
    "start_time = time.time()\n",
    "output = model.generate(**inputs, max_new_tokens=500, do_sample=False)\n",
    "end_time = time.time()\n",
    "\n",
    "generation_time = end_time - start_time\n",
    "num_generated_tokens = len(output[0]) - len(inputs.input_ids[0])\n",
    "tokens_per_second = num_generated_tokens / generation_time\n",
    "\n",
    "print(f\"Generated {num_generated_tokens} tokens in {generation_time:.2f}s ({tokens_per_second:.2f} tokens/s)\")\n",
    "\n",
    "print(processor.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a939124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 49.62 FPS\n",
    "# 54.36 Random\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fna_torch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
