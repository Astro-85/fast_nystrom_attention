{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7777a961",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrew/miniconda3/envs/fna_torch3d/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as mpatches\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from einops import rearrange\n",
    "\n",
    "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration\n",
    "\n",
    "sys.path.append('../..')\n",
    "from fast_nystrom_attention import LlavaNextForConditionalGenerationFNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0936aba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19586c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"llava-hf/llava-v1.6-vicuna-7b-hf\"\n",
    "DTYPE = torch.float32\n",
    "DEVICE = torch.device(\"cuda:0\")\n",
    "fna_config = {\n",
    "    'fna_layers': range(12, 32),\n",
    "    'num_sample': 256,\n",
    "    'resample_fps': False,\n",
    "}\n",
    "\n",
    "processor = LlavaNextProcessor.from_pretrained(MODEL_ID, use_fast=False)\n",
    "model = LlavaNextForConditionalGenerationFNA.from_pretrained(\n",
    "    MODEL_ID, \n",
    "    fna_config=fna_config, \n",
    "    torch_dtype=DTYPE, \n",
    "    device_map=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2a879f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 500 tokens in 14.27s (35.03 tokens/s)\n",
      "USER: \n",
      "Write a story about this image. ASSISTANT: The image shows a serene scene of a forest path. The path is lined with trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is flanked by trees, and the ground is covered in fallen leaves. The path is\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "image = Image.open('forest.jpg')\n",
    "\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": \"Write a story about this image.\"},\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)\n",
    "inputs = processor(image, prompt, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "# autoregressively complete prompt\n",
    "start_time = time.time()\n",
    "output = model.generate(**inputs, max_new_tokens=500, do_sample=False)\n",
    "end_time = time.time()\n",
    "\n",
    "generation_time = end_time - start_time\n",
    "num_generated_tokens = len(output[0]) - len(inputs.input_ids[0])\n",
    "tokens_per_second = num_generated_tokens / generation_time\n",
    "\n",
    "print(f\"Generated {num_generated_tokens} tokens in {generation_time:.2f}s ({tokens_per_second:.2f} tokens/s)\")\n",
    "\n",
    "print(processor.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a939124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fna_torch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
